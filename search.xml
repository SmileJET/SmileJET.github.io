<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>论文阅读</title>
    <url>/SmileJet/2020/04/19/read-list/</url>
    <content><![CDATA[<h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="【2019-ICCV】【GitHub】FCOS-Fully-Convolutional-One-Stage-Object-Detection"><a href="#【2019-ICCV】【GitHub】FCOS-Fully-Convolutional-One-Stage-Object-Detection" class="headerlink" title="【2019 ICCV】【GitHub】FCOS: Fully Convolutional One-Stage Object Detection"></a>【2019 ICCV】<a href="https://github.com/tianzhi0549/FCOS" target="_blank" rel="noopener">【GitHub】</a>FCOS: Fully Convolutional One-Stage Object Detection</h2><p>以图像分割的方式解决目标检测问题。<br><img src="/SmileJet/2020/04/19/read-list/image-20200419231953985.png" alt="image-20200419231953985"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115251385.png" alt="image-20200420115251385"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115305609.png" alt="image-20200420115305609"></p>
<h1 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h1><h2 id="【2020-CVPR】【GitHub】-PolarMask-Single-Shot-Instance-Segmentation-with-Polar-Representation"><a href="#【2020-CVPR】【GitHub】-PolarMask-Single-Shot-Instance-Segmentation-with-Polar-Representation" class="headerlink" title="【2020 CVPR】【GitHub】 PolarMask: Single Shot Instance Segmentation with Polar Representation"></a>【2020 CVPR】<a href="https://github.com/xieenze/PolarMask" target="_blank" rel="noopener">【GitHub】</a> PolarMask: Single Shot Instance Segmentation with Polar Representation</h2><p>基于FCOS实现实例分割，使用极坐标表达实例的轮廓，进一步形成分割结果。</p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115345921.png" alt="image-20200420115345921"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115439081.png" alt="image-20200420115439081"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115451575.png" alt="image-20200420115451575"></p>
<h2 id="【2020-CVPR】-CenterMask-single-shot-instance-segmentation-with-point-representation"><a href="#【2020-CVPR】-CenterMask-single-shot-instance-segmentation-with-point-representation" class="headerlink" title="【2020 CVPR】 CenterMask: single shot instance segmentation with point representation"></a>【2020 CVPR】 CenterMask: single shot instance segmentation with point representation</h2><p>引入局部形状预测和全局显著性预测，分别预测每个物体的形状和全局下都有哪些物体，一个负责局部一个负责全局</p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115531014.png" alt="image-20200420115531014"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115548245.png" alt="image-20200420115548245"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115605745.png" alt="image-20200420115605745"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115615742.png" alt="image-20200420115615742"></p>
<h2 id="【2020-CVPR】【GitHub】-Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing"><a href="#【2020-CVPR】【GitHub】-Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing" class="headerlink" title="【2020 CVPR】【GitHub】 Strip Pooling: Rethinking Spatial Pooling for Scene Parsing"></a>【2020 CVPR】<a href="https://github.com/Andrew-Qibin/SPNet" target="_blank" rel="noopener">【GitHub】</a> Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</h2><p>提出条状Pooling，相比于方形卷积，可以较好检测到长条形物体</p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115653369.png" alt="image-20200420115653369"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115704116.png" alt="image-20200420115704116"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115715342.png" alt="image-20200420115715342"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115724747.png" alt="image-20200420115724747"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115733985.png" alt="image-20200420115733985"></p>
<h2 id="【2020】An-automatic-COVID-19-CT-segmentation-based-on-U-Net-with-attention-mechanism"><a href="#【2020】An-automatic-COVID-19-CT-segmentation-based-on-U-Net-with-attention-mechanism" class="headerlink" title="【2020】An automatic COVID-19 CT segmentation based on U-Net with attention mechanism"></a>【2020】An automatic COVID-19 CT segmentation based on U-Net with attention mechanism</h2><p>新型冠状病毒分割<br>在unet基础上做修改：</p>
<ul>
<li><p>加入注意力机制（通道+空间）</p>
</li>
<li><p>focal tversky loss（检测小区域的病灶位置）<br><img src="/SmileJet/2020/04/19/read-list/image-20200420115811144.png" alt="image-20200420115811144"></p>
</li>
</ul>
<p>Res_dil block（提高感受野）：</p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115853141.png" alt="image-20200420115853141"></p>
<p>注意力机制：</p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115917105.png" alt="image-20200420115917105"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115931445.png" alt="image-20200420115931445"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420115946281.png" alt="image-20200420115946281"></p>
<h2 id="【2019-CVPR】【GitHub】-Dual-Attention-Network-for-Scene-Segmentation"><a href="#【2019-CVPR】【GitHub】-Dual-Attention-Network-for-Scene-Segmentation" class="headerlink" title="【2019 CVPR】【GitHub】 Dual Attention Network for Scene Segmentation"></a>【2019 CVPR】<a href="https://github.com/junfu1115/DANet/" target="_blank" rel="noopener">【GitHub】</a> Dual Attention Network for Scene Segmentation</h2><p>加入注意力机制，同时对空间和通道进行。</p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420120019703.png" alt="image-20200420120019703"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420120052772.png" alt="image-20200420120052772"></p>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420120101963.png" alt="image-20200420120101963"></p>
<h1 id="图像翻译"><a href="#图像翻译" class="headerlink" title="图像翻译"></a>图像翻译</h1><h2 id="【2020-ICLR】【GitHub】U-GAT-IT-Unsupervised-Generative-Attentional-Networks-with-Adaptive-Layer-Instance-Normalization-for-Image-to-Image-Translation"><a href="#【2020-ICLR】【GitHub】U-GAT-IT-Unsupervised-Generative-Attentional-Networks-with-Adaptive-Layer-Instance-Normalization-for-Image-to-Image-Translation" class="headerlink" title="【2020 ICLR】【GitHub】U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation"></a>【2020 ICLR】<a href="https://github.com/znxlwm/UGATIT-pytorch" target="_blank" rel="noopener">【GitHub】</a>U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation</h2><p><a href="http://www.twistedwg.com/2019/08/07/UGATIT.html" target="_blank" rel="noopener">UGATIT-自适应图层实例归一化下图像到图像转换</a><br><a href="http://39.108.217.36/index.php/archives/392/" target="_blank" rel="noopener">论文笔记</a></p>
<p>引入<code>注意力机制</code>，这里采用全局和平均池化的类激活图（Class Activation Map-CAM）来实现的，通过CNN确定分类依据的位置。<br>加入<code>自适应图层实例归一化</code>（AdaLIN），帮助注意力引导模型灵活控制形状和纹理变化量。</p>
<p>CAM 的意义就是以热力图的形式告诉我们，模型通过哪些像素点得知图片属于某个类别。<br>特征图经过 GAP 处理后每一个特征图包含了不同类别的信息，权重 w 对应分类时的权重。绘制热力图时，提取出所有的权重，往回找到对应的特征图，然后进行加权求和即可。<br><img src="/SmileJet/2020/04/19/read-list/image-20200420120144704.png" alt="image-20200420120144704"></p>
<p>网络结构由一个生成器和两个判别器组成。<br>判别器的设计采用一个全局判别器(Global Discriminator)以及一个局部判别器(Local Discriminator)结合实现，所谓的全局判别器和局部判别器的区别就在于全局判别器对输入的图像进行了更深层次的特征压缩，最后输出的前一层。<br><img src="/SmileJet/2020/04/19/read-list/image-20200420120158234.png" alt="image-20200420120158234"><br><img src="/SmileJet/2020/04/19/read-list/image-20200420120213245.png" alt="image-20200420120213245"></p>
<p>此处要提一下，在判别器中也加入了CAM模块，虽然在判别器下CAM并没有做域的分类，但是加入注意力模块对于判别图像真伪是有益的，文中给出的解释是注意力图通过关注目标域中的真实图像和伪图像之间的差异来帮助进行微调。</p>
<p>损失函数：</p>
<ul>
<li>GAN的对抗损失</li>
<li>循环一致性损失</li>
<li>身份损失（相同域之间不希望进行转换）</li>
<li>CAM损失（生成器中对图像域进行分类，希望源域和目标域尽可能分开）</li>
</ul>
<p><img src="/SmileJet/2020/04/19/read-list/image-20200420120247952.png" alt="image-20200420120247952"></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
</search>
