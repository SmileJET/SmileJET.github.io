<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>论文阅读</title>
    <url>/read-list/</url>
    <content><![CDATA[<h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="【2019-ICCV】【GitHub】FCOS-Fully-Convolutional-One-Stage-Object-Detection"><a href="#【2019-ICCV】【GitHub】FCOS-Fully-Convolutional-One-Stage-Object-Detection" class="headerlink" title="【2019 ICCV】【GitHub】FCOS: Fully Convolutional One-Stage Object Detection"></a>【2019 ICCV】<a href="https://github.com/tianzhi0549/FCOS" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a>FCOS: Fully Convolutional One-Stage Object Detection</h2><p>以图像分割的方式解决目标检测问题。<br><img src="/read-list/image-20200419231953985.png" alt="image-20200419231953985"></p>
<p><img src="/read-list/image-20200420115251385.png" alt="image-20200420115251385"></p>
<p><img src="/read-list/image-20200420115305609.png" alt="image-20200420115305609"></p>
<h1 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h1><h2 id="【2020-CVPR】【GitHub】-PolarMask-Single-Shot-Instance-Segmentation-with-Polar-Representation"><a href="#【2020-CVPR】【GitHub】-PolarMask-Single-Shot-Instance-Segmentation-with-Polar-Representation" class="headerlink" title="【2020 CVPR】【GitHub】 PolarMask: Single Shot Instance Segmentation with Polar Representation"></a>【2020 CVPR】<a href="https://github.com/xieenze/PolarMask" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a> PolarMask: Single Shot Instance Segmentation with Polar Representation</h2><p>基于FCOS实现实例分割，使用极坐标表达实例的轮廓，进一步形成分割结果。</p>
<p><img src="/read-list/image-20200420115345921.png" alt="image-20200420115345921"></p>
<p><img src="/read-list/image-20200420115439081.png" alt="image-20200420115439081"></p>
<p><img src="/read-list/image-20200420115451575.png" alt="image-20200420115451575"></p>
<h2 id="【2020-CVPR】-CenterMask-single-shot-instance-segmentation-with-point-representation"><a href="#【2020-CVPR】-CenterMask-single-shot-instance-segmentation-with-point-representation" class="headerlink" title="【2020 CVPR】 CenterMask: single shot instance segmentation with point representation"></a>【2020 CVPR】 CenterMask: single shot instance segmentation with point representation</h2><p>引入局部形状预测和全局显著性预测，分别预测每个物体的形状和全局下都有哪些物体，一个负责局部一个负责全局</p>
<p><img src="/read-list/image-20200420115531014.png" alt="image-20200420115531014"></p>
<p><img src="/read-list/image-20200420115548245.png" alt="image-20200420115548245"></p>
<p><img src="/read-list/image-20200420115605745.png" alt="image-20200420115605745"></p>
<p><img src="/read-list/image-20200420115615742.png" alt="image-20200420115615742"></p>
<h2 id="【2020-CVPR】【GitHub】-Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing"><a href="#【2020-CVPR】【GitHub】-Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing" class="headerlink" title="【2020 CVPR】【GitHub】 Strip Pooling: Rethinking Spatial Pooling for Scene Parsing"></a>【2020 CVPR】<a href="https://github.com/Andrew-Qibin/SPNet" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a> Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</h2><p>提出条状Pooling，相比于方形卷积，可以较好检测到长条形物体</p>
<p><img src="/read-list/image-20200420115653369.png" alt="image-20200420115653369"></p>
<p><img src="/read-list/image-20200420115704116.png" alt="image-20200420115704116"></p>
<p><img src="/read-list/image-20200420115715342.png" alt="image-20200420115715342"></p>
<p><img src="/read-list/image-20200420115724747.png" alt="image-20200420115724747"></p>
<p><img src="/read-list/image-20200420115733985.png" alt="image-20200420115733985"></p>
<h2 id="【2020】An-automatic-COVID-19-CT-segmentation-based-on-U-Net-with-attention-mechanism"><a href="#【2020】An-automatic-COVID-19-CT-segmentation-based-on-U-Net-with-attention-mechanism" class="headerlink" title="【2020】An automatic COVID-19 CT segmentation based on U-Net with attention mechanism"></a>【2020】An automatic COVID-19 CT segmentation based on U-Net with attention mechanism</h2><p>新型冠状病毒分割<br>在unet基础上做修改：</p>
<ul>
<li><p>加入注意力机制（通道+空间）</p>
</li>
<li><p>focal tversky loss（检测小区域的病灶位置）<br><img src="/read-list/image-20200420115811144.png" alt="image-20200420115811144"></p>
</li>
</ul>
<p>Res_dil block（提高感受野）：</p>
<p><img src="/read-list/image-20200420115853141.png" alt="image-20200420115853141"></p>
<p>注意力机制：</p>
<p><img src="/read-list/image-20200420115917105.png" alt="image-20200420115917105"></p>
<p><img src="/read-list/image-20200420115931445.png" alt="image-20200420115931445"></p>
<p><img src="/read-list/image-20200420115946281.png" alt="image-20200420115946281"></p>
<h2 id="【2019-CVPR】【GitHub】-Dual-Attention-Network-for-Scene-Segmentation"><a href="#【2019-CVPR】【GitHub】-Dual-Attention-Network-for-Scene-Segmentation" class="headerlink" title="【2019 CVPR】【GitHub】 Dual Attention Network for Scene Segmentation"></a>【2019 CVPR】<a href="https://github.com/junfu1115/DANet/" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a> Dual Attention Network for Scene Segmentation</h2><p>加入注意力机制，同时对空间和通道进行。</p>
<p><img src="/read-list/image-20200420120019703.png" alt="image-20200420120019703"></p>
<p><img src="/read-list/image-20200420120052772.png" alt="image-20200420120052772"></p>
<p><img src="/read-list/image-20200420120101963.png" alt="image-20200420120101963"></p>
<h1 id="图像翻译"><a href="#图像翻译" class="headerlink" title="图像翻译"></a>图像翻译</h1><h2 id="【2020-ICLR】【GitHub】U-GAT-IT-Unsupervised-Generative-Attentional-Networks-with-Adaptive-Layer-Instance-Normalization-for-Image-to-Image-Translation"><a href="#【2020-ICLR】【GitHub】U-GAT-IT-Unsupervised-Generative-Attentional-Networks-with-Adaptive-Layer-Instance-Normalization-for-Image-to-Image-Translation" class="headerlink" title="【2020 ICLR】【GitHub】U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation"></a>【2020 ICLR】<a href="https://github.com/znxlwm/UGATIT-pytorch" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a>U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation</h2><p><a href="http://www.twistedwg.com/2019/08/07/UGATIT.html" target="_blank" rel="external nofollow noopener noreferrer">UGATIT-自适应图层实例归一化下图像到图像转换</a><br><a href="http://39.108.217.36/index.php/archives/392/" target="_blank" rel="external nofollow noopener noreferrer">论文笔记</a></p>
<p>引入<code>注意力机制</code>，这里采用全局和平均池化的类激活图（Class Activation Map-CAM）来实现的，通过CNN确定分类依据的位置。<br>加入<code>自适应图层实例归一化</code>（AdaLIN），帮助注意力引导模型灵活控制形状和纹理变化量。</p>
<p>CAM 的意义就是以热力图的形式告诉我们，模型通过哪些像素点得知图片属于某个类别。<br>特征图经过 GAP 处理后每一个特征图包含了不同类别的信息，权重 w 对应分类时的权重。绘制热力图时，提取出所有的权重，往回找到对应的特征图，然后进行加权求和即可。<br><img src="/read-list/image-20200420120144704.png" alt="image-20200420120144704"></p>
<p>网络结构由一个生成器和两个判别器组成。<br>判别器的设计采用一个全局判别器(Global Discriminator)以及一个局部判别器(Local Discriminator)结合实现，所谓的全局判别器和局部判别器的区别就在于全局判别器对输入的图像进行了更深层次的特征压缩，最后输出的前一层。<br><img src="/read-list/image-20200420120158234.png" alt="image-20200420120158234"><br><img src="/read-list/image-20200420120213245.png" alt="image-20200420120213245"></p>
<p>此处要提一下，在判别器中也加入了CAM模块，虽然在判别器下CAM并没有做域的分类，但是加入注意力模块对于判别图像真伪是有益的，文中给出的解释是注意力图通过关注目标域中的真实图像和伪图像之间的差异来帮助进行微调。</p>
<p>损失函数：</p>
<ul>
<li>GAN的对抗损失</li>
<li>循环一致性损失</li>
<li>身份损失（相同域之间不希望进行转换）</li>
<li>CAM损失（生成器中对图像域进行分类，希望源域和目标域尽可能分开）</li>
</ul>
<p><img src="/read-list/image-20200420120247952.png" alt="image-20200420120247952"></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>【牛客网】数据库</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%9B%E5%AE%A2%E7%BD%91%E5%88%B7%E9%A2%98/</url>
    <content><![CDATA[<h1 id="数据库管理系统是数据库系统的核心"><a href="#数据库管理系统是数据库系统的核心" class="headerlink" title="数据库管理系统是数据库系统的核心"></a>数据库管理系统是数据库系统的核心</h1><p>数据库系统由数据库（数据）、数据库管理系统（软件）、数据库管理员（人员）、硬件平台（硬件）、软件平台5个部分构成。</p>
<p><strong>数据库管理系统</strong>是数据库系统的核心，负责数据库中的数据组织、数据操作、数据维护、控制及保护和数据服务等工作。</p>
<h1 id="数据库的外模式-模式映像，保证了数据与程序的逻辑独立性。"><a href="#数据库的外模式-模式映像，保证了数据与程序的逻辑独立性。" class="headerlink" title="数据库的外模式/模式映像，保证了数据与程序的逻辑独立性。"></a>数据库的外模式/模式映像，保证了数据与程序的逻辑独立性。</h1><p>外模式/模式映像定义了数据库中不同用户的外模式与数据库逻辑模式之间的对应关系。当数据库模式发生变化时，通过调整外模式/模式映像间的映像关系，使得应用程序不必随之修改，从而保证数据与应用程序间的逻辑独立性，简称数据的逻辑独立性。</p>
<p>模式又称逻辑模式，模式/内模式映像定义了数据库中数据全局逻辑结构与这些数据在系统中的物理存储组织结构之间的对应关系，保证数据库中数据与应用程序间的物理独立性。</p>
<h1 id="若事务-T-对数据对象-A-加上-S-锁，则（-）。"><a href="#若事务-T-对数据对象-A-加上-S-锁，则（-）。" class="headerlink" title="若事务 T 对数据对象 A 加上 S 锁，则（ ）。"></a>若事务 T 对数据对象 A 加上 S 锁，则（ ）。</h1><p>事务T可以读A但不能修改A，其它事务只能再对A加S锁，而不能加X 锁。</p>
<p>S锁为共享锁，X锁为排他锁。</p>
<p>共享锁又称为读锁，若事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。</p>
<h1 id="关系的5条性质"><a href="#关系的5条性质" class="headerlink" title="关系的5条性质"></a>关系的5条性质</h1><ol>
<li>分量必须取原子值，每个分量必须是不可再分的数据项。</li>
<li>列是同质的，每列中的分量必须是同一类型的数据，来自同一个域。</li>
<li>属性不能重名。</li>
<li>行列的顺序无关。</li>
<li>任何两个元组不能完全相同，这是由主码约束来保证的。但是有些数据库若用户没有定义完整性约束条件，允许有两行以上的相同的元组。</li>
</ol>
<h1 id="在关系模式-R分解成数据库模式ρ时，谈论无损联接的先决条件是存在（泛关系）。"><a href="#在关系模式-R分解成数据库模式ρ时，谈论无损联接的先决条件是存在（泛关系）。" class="headerlink" title="在关系模式 R分解成数据库模式ρ时，谈论无损联接的先决条件是存在（泛关系）。"></a>在关系模式 R分解成数据库模式ρ时，谈论无损联接的先决条件是存在（泛关系）。</h1>]]></content>
      <categories>
        <category>知识点</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>知识点</tag>
        <tag>牛客网</tag>
        <tag>刷题</tag>
      </tags>
  </entry>
  <entry>
    <title>白盒测试：语句覆盖、条件覆盖（分支覆盖）、判定覆盖、条件-判定覆盖、组合覆盖、路径覆盖的区别</title>
    <url>/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h1 id="语句覆盖"><a href="#语句覆盖" class="headerlink" title="语句覆盖"></a>语句覆盖</h1><p><strong>每个可执行语句都走一遍即可，即测试用例要覆盖所有的语句</strong>（来源：软件开发的技术基础）</p>
<a id="more"></a>

<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916.jpg" alt="img"></p>
<h1 id="判定覆盖（分支覆盖）"><a href="#判定覆盖（分支覆盖）" class="headerlink" title="判定覆盖（分支覆盖）"></a>判定覆盖（分支覆盖）</h1><p>针对判断语句，在设定案例的时候，要设定True和False的两种案例；与语句覆盖不同的是增加了False的情况。</p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460107267.jpg" alt="img"></p>
<h1 id="条件覆盖"><a href="#条件覆盖" class="headerlink" title="条件覆盖"></a>条件覆盖</h1><p>针对判断语句里面案例的取值都要去一次，不考虑条件的取值</p>
<p><strong>另注</strong>：条件覆盖保证判断中的每个条件都被覆盖（来源：软件开发的技术基础）</p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460180539.jpg" alt="img"></p>
<h1 id="判定-条件覆盖"><a href="#判定-条件覆盖" class="headerlink" title="判定/条件覆盖"></a>判定/条件覆盖</h1><p>判定覆盖各条件覆盖交叉，针对于判定中的条件取值 </p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460218160.jpg" alt="img"></p>
<h1 id="条件组合覆盖"><a href="#条件组合覆盖" class="headerlink" title="条件组合覆盖"></a>条件组合覆盖</h1><p>判定-条件覆盖的加强版 </p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460241521.jpg" alt="img"></p>
<h1 id="路径覆盖"><a href="#路径覆盖" class="headerlink" title="路径覆盖"></a>路径覆盖</h1><p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460268368.jpg" alt="img"></p>
]]></content>
      <categories>
        <category>知识点</category>
      </categories>
      <tags>
        <tag>软件测试</tag>
        <tag>白盒测试</tag>
      </tags>
  </entry>
</search>
