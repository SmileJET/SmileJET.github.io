<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>论文阅读</title>
    <url>/read-list/</url>
    <content><![CDATA[<h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="【2019-ICCV】【GitHub】FCOS-Fully-Convolutional-One-Stage-Object-Detection"><a href="#【2019-ICCV】【GitHub】FCOS-Fully-Convolutional-One-Stage-Object-Detection" class="headerlink" title="【2019 ICCV】【GitHub】FCOS: Fully Convolutional One-Stage Object Detection"></a>【2019 ICCV】<a href="https://github.com/tianzhi0549/FCOS" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a>FCOS: Fully Convolutional One-Stage Object Detection</h2><p>以图像分割的方式解决目标检测问题。<br><img src="/read-list/image-20200419231953985.png" alt="image-20200419231953985"></p>
<p><img src="/read-list/image-20200420115251385.png" alt="image-20200420115251385"></p>
<p><img src="/read-list/image-20200420115305609.png" alt="image-20200420115305609"></p>
<h1 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h1><h2 id="【2020-CVPR】【GitHub】-PolarMask-Single-Shot-Instance-Segmentation-with-Polar-Representation"><a href="#【2020-CVPR】【GitHub】-PolarMask-Single-Shot-Instance-Segmentation-with-Polar-Representation" class="headerlink" title="【2020 CVPR】【GitHub】 PolarMask: Single Shot Instance Segmentation with Polar Representation"></a>【2020 CVPR】<a href="https://github.com/xieenze/PolarMask" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a> PolarMask: Single Shot Instance Segmentation with Polar Representation</h2><p>基于FCOS实现实例分割，使用极坐标表达实例的轮廓，进一步形成分割结果。</p>
<p><img src="/read-list/image-20200420115345921.png" alt="image-20200420115345921"></p>
<p><img src="/read-list/image-20200420115439081.png" alt="image-20200420115439081"></p>
<p><img src="/read-list/image-20200420115451575.png" alt="image-20200420115451575"></p>
<h2 id="【2020-CVPR】-CenterMask-single-shot-instance-segmentation-with-point-representation"><a href="#【2020-CVPR】-CenterMask-single-shot-instance-segmentation-with-point-representation" class="headerlink" title="【2020 CVPR】 CenterMask: single shot instance segmentation with point representation"></a>【2020 CVPR】 CenterMask: single shot instance segmentation with point representation</h2><p>引入局部形状预测和全局显著性预测，分别预测每个物体的形状和全局下都有哪些物体，一个负责局部一个负责全局</p>
<p><img src="/read-list/image-20200420115531014.png" alt="image-20200420115531014"></p>
<p><img src="/read-list/image-20200420115548245.png" alt="image-20200420115548245"></p>
<p><img src="/read-list/image-20200420115605745.png" alt="image-20200420115605745"></p>
<p><img src="/read-list/image-20200420115615742.png" alt="image-20200420115615742"></p>
<h2 id="【2020-CVPR】【GitHub】-Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing"><a href="#【2020-CVPR】【GitHub】-Strip-Pooling-Rethinking-Spatial-Pooling-for-Scene-Parsing" class="headerlink" title="【2020 CVPR】【GitHub】 Strip Pooling: Rethinking Spatial Pooling for Scene Parsing"></a>【2020 CVPR】<a href="https://github.com/Andrew-Qibin/SPNet" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a> Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</h2><p>提出条状Pooling，相比于方形卷积，可以较好检测到长条形物体</p>
<p><img src="/read-list/image-20200420115653369.png" alt="image-20200420115653369"></p>
<p><img src="/read-list/image-20200420115704116.png" alt="image-20200420115704116"></p>
<p><img src="/read-list/image-20200420115715342.png" alt="image-20200420115715342"></p>
<p><img src="/read-list/image-20200420115724747.png" alt="image-20200420115724747"></p>
<p><img src="/read-list/image-20200420115733985.png" alt="image-20200420115733985"></p>
<h2 id="【2020】An-automatic-COVID-19-CT-segmentation-based-on-U-Net-with-attention-mechanism"><a href="#【2020】An-automatic-COVID-19-CT-segmentation-based-on-U-Net-with-attention-mechanism" class="headerlink" title="【2020】An automatic COVID-19 CT segmentation based on U-Net with attention mechanism"></a>【2020】An automatic COVID-19 CT segmentation based on U-Net with attention mechanism</h2><p>新型冠状病毒分割<br>在unet基础上做修改：</p>
<ul>
<li><p>加入注意力机制（通道+空间）</p>
</li>
<li><p>focal tversky loss（检测小区域的病灶位置）<br><img src="/read-list/image-20200420115811144.png" alt="image-20200420115811144"></p>
</li>
</ul>
<p>Res_dil block（提高感受野）：</p>
<p><img src="/read-list/image-20200420115853141.png" alt="image-20200420115853141"></p>
<p>注意力机制：</p>
<p><img src="/read-list/image-20200420115917105.png" alt="image-20200420115917105"></p>
<p><img src="/read-list/image-20200420115931445.png" alt="image-20200420115931445"></p>
<p><img src="/read-list/image-20200420115946281.png" alt="image-20200420115946281"></p>
<h2 id="【2019-CVPR】【GitHub】-Dual-Attention-Network-for-Scene-Segmentation"><a href="#【2019-CVPR】【GitHub】-Dual-Attention-Network-for-Scene-Segmentation" class="headerlink" title="【2019 CVPR】【GitHub】 Dual Attention Network for Scene Segmentation"></a>【2019 CVPR】<a href="https://github.com/junfu1115/DANet/" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a> Dual Attention Network for Scene Segmentation</h2><p>加入注意力机制，同时对空间和通道进行。</p>
<p><img src="/read-list/image-20200420120019703.png" alt="image-20200420120019703"></p>
<p><img src="/read-list/image-20200420120052772.png" alt="image-20200420120052772"></p>
<p><img src="/read-list/image-20200420120101963.png" alt="image-20200420120101963"></p>
<h1 id="图像翻译"><a href="#图像翻译" class="headerlink" title="图像翻译"></a>图像翻译</h1><h2 id="【2020-ICLR】【GitHub】U-GAT-IT-Unsupervised-Generative-Attentional-Networks-with-Adaptive-Layer-Instance-Normalization-for-Image-to-Image-Translation"><a href="#【2020-ICLR】【GitHub】U-GAT-IT-Unsupervised-Generative-Attentional-Networks-with-Adaptive-Layer-Instance-Normalization-for-Image-to-Image-Translation" class="headerlink" title="【2020 ICLR】【GitHub】U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation"></a>【2020 ICLR】<a href="https://github.com/znxlwm/UGATIT-pytorch" target="_blank" rel="external nofollow noopener noreferrer">【GitHub】</a>U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation</h2><p><a href="http://www.twistedwg.com/2019/08/07/UGATIT.html" target="_blank" rel="external nofollow noopener noreferrer">UGATIT-自适应图层实例归一化下图像到图像转换</a><br><a href="http://39.108.217.36/index.php/archives/392/" target="_blank" rel="external nofollow noopener noreferrer">论文笔记</a></p>
<p>引入<code>注意力机制</code>，这里采用全局和平均池化的类激活图（Class Activation Map-CAM）来实现的，通过CNN确定分类依据的位置。<br>加入<code>自适应图层实例归一化</code>（AdaLIN），帮助注意力引导模型灵活控制形状和纹理变化量。</p>
<p>CAM 的意义就是以热力图的形式告诉我们，模型通过哪些像素点得知图片属于某个类别。<br>特征图经过 GAP 处理后每一个特征图包含了不同类别的信息，权重 w 对应分类时的权重。绘制热力图时，提取出所有的权重，往回找到对应的特征图，然后进行加权求和即可。<br><img src="/read-list/image-20200420120144704.png" alt="image-20200420120144704"></p>
<p>网络结构由一个生成器和两个判别器组成。<br>判别器的设计采用一个全局判别器(Global Discriminator)以及一个局部判别器(Local Discriminator)结合实现，所谓的全局判别器和局部判别器的区别就在于全局判别器对输入的图像进行了更深层次的特征压缩，最后输出的前一层。<br><img src="/read-list/image-20200420120158234.png" alt="image-20200420120158234"><br><img src="/read-list/image-20200420120213245.png" alt="image-20200420120213245"></p>
<p>此处要提一下，在判别器中也加入了CAM模块，虽然在判别器下CAM并没有做域的分类，但是加入注意力模块对于判别图像真伪是有益的，文中给出的解释是注意力图通过关注目标域中的真实图像和伪图像之间的差异来帮助进行微调。</p>
<p>损失函数：</p>
<ul>
<li>GAN的对抗损失</li>
<li>循环一致性损失</li>
<li>身份损失（相同域之间不希望进行转换）</li>
<li>CAM损失（生成器中对图像域进行分类，希望源域和目标域尽可能分开）</li>
</ul>
<p><img src="/read-list/image-20200420120247952.png" alt="image-20200420120247952"></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>白盒测试：语句覆盖、条件覆盖（分支覆盖）、判定覆盖、条件-判定覆盖、组合覆盖、路径覆盖的区别</title>
    <url>/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h1 id="语句覆盖"><a href="#语句覆盖" class="headerlink" title="语句覆盖"></a>语句覆盖</h1><p><strong>每个可执行语句都走一遍即可，即测试用例要覆盖所有的语句</strong>（来源：软件开发的技术基础）</p>
<a id="more"></a>

<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916.jpg" alt="img"></p>
<h1 id="判定覆盖（分支覆盖）"><a href="#判定覆盖（分支覆盖）" class="headerlink" title="判定覆盖（分支覆盖）"></a>判定覆盖（分支覆盖）</h1><p>针对判断语句，在设定案例的时候，要设定True和False的两种案例；与语句覆盖不同的是增加了False的情况。</p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460107267.jpg" alt="img"></p>
<h1 id="条件覆盖"><a href="#条件覆盖" class="headerlink" title="条件覆盖"></a>条件覆盖</h1><p>针对判断语句里面案例的取值都要去一次，不考虑条件的取值</p>
<p><strong>另注</strong>：条件覆盖保证判断中的每个条件都被覆盖（来源：软件开发的技术基础）</p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460180539.jpg" alt="img"></p>
<h1 id="判定-条件覆盖"><a href="#判定-条件覆盖" class="headerlink" title="判定/条件覆盖"></a>判定/条件覆盖</h1><p>判定覆盖各条件覆盖交叉，针对于判定中的条件取值 </p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460218160.jpg" alt="img"></p>
<h1 id="条件组合覆盖"><a href="#条件组合覆盖" class="headerlink" title="条件组合覆盖"></a>条件组合覆盖</h1><p>判定-条件覆盖的加强版 </p>
<p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460241521.jpg" alt="img"></p>
<h1 id="路径覆盖"><a href="#路径覆盖" class="headerlink" title="路径覆盖"></a>路径覆盖</h1><p><img src="/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/5de1f30e76c66137ee061916-1587460268368.jpg" alt="img"></p>
]]></content>
      <categories>
        <category>知识点</category>
      </categories>
      <tags>
        <tag>软件测试</tag>
        <tag>白盒测试</tag>
      </tags>
  </entry>
</search>
